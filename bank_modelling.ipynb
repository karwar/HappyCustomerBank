{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data, spliting the data set into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81385, 55)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data1.csv', encoding = \"latin1\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['Disbursed']\n",
    "X = data\n",
    "del X['Disbursed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80112\n",
       "1     1273\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60067\n",
       "1      971\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20045\n",
       "1      302\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simple logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with logistic regression. Logistic regression with all parameters set on defaults yields all zeros. It turned out that penalty = 'l1' helps more then class_weigts='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9911475097229653\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_train)[:,1]\n",
    "print( \"AUC: \", roc_auc_score(y_score=y_pred,y_true=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremly high AUC results from a high FPR, which in turn is caused by considerable classes imbalance. From now on we will focus on F1 score instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing excess variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if thanks to l1 penalty we will be able to remove some unnecessary variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = (model.coef_==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        'Salary_Account_Punjab National Bank', 0, 0, 'Mobile_Verified_Y',\n",
       "        0, 0, 0, 'Var2_D', 0, 'Var2_F', 0, 0, 'Source_S127', 0, 0, 0, 0,\n",
       "        0, 0, 0, 'City2_Co', 0, 'City2_G', 0, 0, 0, 0, 'City2_O', 0, 0,\n",
       "        0, 0, 0, 'var11_F', 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(z,data.columns,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 variables which could be removed (I am leaving them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['Salary_Account_Punjab National Bank']\n",
    "del X['Mobile_Verified_Y']\n",
    "del X['Var2_D']\n",
    "del X['Var2_F']\n",
    "del X['Source_S127']\n",
    "del X['City2_Co']\n",
    "del X['City2_G']\n",
    "del X['City2_O']\n",
    "del X['var11_F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results of log regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the result will be on train set (cut-off threshold = 0.5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function which draw confusion matrix in a nicer form\n",
    "def print_conf(a):\n",
    "    a_list=a.tolist()\n",
    "    a_list[0].insert(0,'Real 0')\n",
    "    a_list[1].insert(0,'Real 1')\n",
    "    print (tabulate (a_list,headers=['Real/Pred','Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          59715       352\n",
      "Real 1            361       610\n",
      "F1: 0.6311433005690635\n"
     ]
    }
   ],
   "source": [
    "predictions = np.where(y_pred>=0.5,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be easily improved (in terms of F1) by manipulating the cut-off threshold. For exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          59302       765\n",
      "Real 1             75       896\n",
      "F1: 0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "predictions = np.where(y_pred>=0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          60067         0\n",
      "Real 1              0       971\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_train)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see symptoms of overfitting. To deal with it, in case of this particular model, we will add a limitation on e.g. min_samples_leaf. In general cross validation will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          59745       322\n",
      "Real 1             66       905\n",
      "F1: 0.8234758871701546\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(min_samples_leaf=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_train)[:,1]\n",
    "predictions = np.where(y_pred>0.3,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing best model in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to fit models one by one, for each model to obtain a vector of probabilities by means of crossvalidation and finaly to establish the best cut off threshold in terms of F1 score. The best model will be one with the best F1 score. For the moment we don't take into consideration changing of specific parametres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0313, 0.6592, 0.6597, 0.6601, 0.6641, 0.6659, 0.6687, 0.6688, 0.6604, 0.6483, 0.606, 0.5414, 0.4627, 0.3646, 0.2596, 0.1333, 0.0455, 0.0102, 0.0021, 0.0]\n",
      "LogisticRegression Best F1: 0.6688 threshold: 0.35000000000000003\n",
      "[0.6129, 0.6129, 0.6129, 0.6103, 0.6166, 0.6119, 0.6079, 0.5967, 0.5853, 0.5713, 0.5581, 0.5581, 0.5124, 0.5099, 0.4843, 0.4744, 0.4412, 0.4282, 0.4077, 0.4077]\n",
      "DecisionTreeClassifier Best F1: 0.6166 threshold: 0.2\n",
      "[0.0313, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592, 0.6592]\n",
      "LinearDiscriminantAnalysis Best F1: 0.6592 threshold: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0315, 0.1618, 0.173, 0.1804, 0.1858, 0.1907, 0.1957, 0.2003, 0.2041, 0.208, 0.2125, 0.2159, 0.22, 0.2245, 0.2296, 0.2345, 0.2418, 0.2497, 0.2603, 0.279]\n",
      "QuadraticDiscriminantAnalysis Best F1: 0.279 threshold: 0.9500000000000001\n",
      "[0.4367, 0.4367, 0.64, 0.64, 0.643, 0.643, 0.607, 0.607, 0.5416, 0.5416, 0.4393, 0.4393, 0.3255, 0.3255, 0.1764, 0.1764, 0.0496, 0.0496, 0.0082, 0.0082]\n",
      "RandomForestClassifier Best F1: 0.643 threshold: 0.2\n",
      "[0.0313, 0.6592, 0.6594, 0.6627, 0.6708, 0.6704, 0.6745, 0.6721, 0.667, 0.6402, 0.6133, 0.5632, 0.5094, 0.4131, 0.2671, 0.1266, 0.0399, 0.0061, 0.0021, 0.0]\n",
      "XGBClassifier Best F1: 0.6745 threshold: 0.30000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kodolamacz/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(penalty='l1'),DecisionTreeClassifier(min_samples_leaf=5), \n",
    "          LinearDiscriminantAnalysis(), \n",
    "          QuadraticDiscriminantAnalysis(), RandomForestClassifier(), XGBClassifier()]\n",
    "m = ['LogisticRegression','DecisionTreeClassifier','LinearDiscriminantAnalysis', \n",
    "          'QuadraticDiscriminantAnalysis', 'RandomForestClassifier', 'XGBClassifier']\n",
    "i = 0\n",
    "for model in models:    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = cross_val_predict(estimator=model, X=X_train, y=y_train, method=\"predict_proba\",cv = StratifiedKFold(3))[:,1]\n",
    "    r = []\n",
    "    for x in  np.arange(0,1,0.05):\n",
    "        z = y_pred > x\n",
    "        z = [int(z[x]) for x in range(len(z))]\n",
    "        f = f1_score(y_train, z)\n",
    "        r.append(round(f,4))\n",
    "    print(r)    \n",
    "    print(m[i], \"Best F1:\", np.max(r),\"threshold:\" ,np.argmax(r)*0.05)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost gave the best result. Experiments showed that manipulating XGBoost parameters doesn't help. Let's establish the very best threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6704, 0.6704, 0.6737, 0.6735, 0.6749, 0.6745, 0.6732, 0.6743, 0.6728, 0.6723]\n",
      "Best F1: 0.6749 threshold: 0.29\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = cross_val_predict(estimator=model, X=X_train, y=y_train, method=\"predict_proba\",cv = StratifiedKFold(3))[:,1]\n",
    "r = []\n",
    "for x in  np.arange(0.25,0.35,0.01):\n",
    "    z = y_pred > x\n",
    "    z = [int(z[x]) for x in range(len(z))]\n",
    "    f = f1_score(y_train, z)\n",
    "    r.append(round(f,4))\n",
    "print(r)    \n",
    "print(\"Best F1:\", np.max(r),\"threshold:\" ,0.25+np.argmax(r)*0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see confusion matrix for the chosen model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          59322       745\n",
      "Real 1             97       874\n",
      "F1: 0.6749034749034749\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.29\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_train, predictions))\n",
    "print(\"F1:\",f1_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real/Pred      Pred 0    Pred 1\n",
      "-----------  --------  --------\n",
      "Real 0          19758       287\n",
      "Real 1             26       276\n",
      "F1: 0.638150289017341\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "threshold = 0.29\n",
    "predictions = np.where(y_pred>threshold,1,0)\n",
    "print_conf(confusion_matrix(y_test, predictions))\n",
    "print(\"F1:\",f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "XGBClassifier() with cut-off threshold = 0.29. FD1 score on the test set = 0.64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
